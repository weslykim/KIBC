 
                                            #2024.6.7 
    캐글 사이트 이용
    타이타닉에 생존한 사람들 혹은 사망한 사람들 코랩을 이용하여 표시
    주택가격 예측하기1


                                            #2024.6.10
    주택가격 예측하기2
    (코랩을 이용)

    Chapter1
    머신 러닝의 개념 : 기계가 패턴을 학습하여 자동화하는 알고리즘
    알고리즘 : 어떠한 문제를 해결하기 위한 일련의 절차나 방법

    머신 러닝의 종류
    지도학습 : 문제와 답을 함께 학습함으로써 미지의 문제에 대한 올바른 답을 예측하는 학습(회귀와 분류로 나뉜다)
    회귀 : 독립변수 x와 종속변수 y의 관계를 함수식으로 설명하는 것
    분류 : 데이터를 어떤 기준에 따라 나누는 기법
    비지도학습 : 조력자의 도움없이 컴퓨터 스스로 학습하는 형태다
    군집 : 기존에 모여있던 데이터에 대해 따로 분류 기준을 주지않고 모델이 스스로 분류 기준을 찾아 집단을 모으는 기법

    머신러닝 환경 구축하기
    주로 python을 이용
    이유 1. 스크립트 언어 :  수정이 쉽고 간단하여 사용자와 지속적인 인터랙션 가능
    2. 쉬운 언어 : 문법 자체가 간단하고 배우기 쉽다.
    3. 머신러닝과 딥러닝의 표준 언어가 파이썬이다.
    
    파이썬 인터프리터 : 파이썬 코드를 해석하고 실행시키기 위한 실행 프로그램(아나콘다)

    코드 편집기 : 파이썬 코드를 수정할때 사용하는 프로그램(주피터, vs코드)

    통계분석및 전처리도구 : 데이터를 로드하고 전처리하기 위한 도구들(NUmpy, Pandasm, Scipy)
    
    시각화도구 : 데이터의 상태를 파악하기 위해 시각화를 지원하는 도구(Matplotlib, seaborn, plotly)

    머신러닝 프레임워크 : 실제 머신러닝 모델을 생성하고 데이터에 적용할 수 있도록 도와주는 도구(사이킷런)

    Chapter2
    데이터의 이해
    피쳐 : 특성이나 특징을 말함
    피쳐의 표기법 테이블 상에서 하나의 열 이름
    데이터 테이블 : 하나의 데이터 묶음(표)

    차원의 저주 : 차원의 증가는 사람뿐만 아니라 컴퓨터도 연산을 어렵게 만든다.
    희박한 벡터 생성 : 0이 너무 많이 포함된 벡터공간
    데이터 처리속도와 메모리 공간 문제 : 데이터가 너무 많아서 처리하는 속도가 느려지거나 메모리의 공간이 굉장이 커진다.

    피쳐의 종류
    연속형 데이터 : 값이 끊어지지 않고 계속 연결되는 종류의 데이터, 실수와 관련된 값이 일반적이다.
    이산형 데이터 : 일종의 라벨로 구분 가능한 데이터로, 연속적 값이 아니라 분리해서 표현하는 데이터

    *Chapter 3, 4, 5, 6은 통계학시간때 같이나감
    Chapter7
    선형회귀의 기초
    선형회귀 : 종속변수 y와 한 개 이상의 독립변수 x와의 선형 상관관계를 모델링하는 회귀 분석기법

    선형회귀의 기초 수식

    비용함수 : 머신러닝에서 최소화해야 할 예측값과 실제값의 차이
    가설함수 : 예측값을 예측하는 함수

    최소자승법으로 선형회귀 풀기
    최소자승법 : 선형대수의 표기법을 사용하여 방정식으로 선형회귀 문제를 푸는방법

    경사하강법으로 선형회귀 풀기
    경사하강법 : 경사를 하강하면서 수식을 최소화하는 매개변수의 값을 찾아내는 방법

    선형회귀 성능 측정하기
    훈련 테스트 분할 : 
    홀드아웃메서드 : 전체 데이터셋에서 일부데이터를 학습 데이터와 테스트 데이터로 나누는 기법

    선형회귀의 성능측정지표
    MAE : 평균 절대잔차로 예측값과 실제값의 차이를 절대값으로 표현하는 지표
    RMSE : 평균제곱근 오차
    결정계수 : 두 개의 값의 증감이 얼마나 일관성을 가지는지 나타내는 지표


                                        #2024.6.11
    
    Chapter8
    선형회귀의 심화

    경사하강법의 종류
    전체-배치 경사하강법 : 각 데이터의 경사도를 모두 더해 하나의 값으로 가중치를 업데이트하는 과정
    모든 데이터를 한번에 입력하는 방식

    특징
    업데이트 횟수 감소 : 효율성 상승
    안정적인 비용함수 수렴
    업데이트 속도 증가 : 메모리 문제 유의

    확률적 경사하강법 :학습용 데이터에서 샘플들을 랜덤으로 뽑아서 가중치를 업데이트하는 과정
    장점
    모델의 성능 변화를 빠르게 확인가능
    데이터의 특성에 따라 훨씬 더 빠르게 결과값 도출가능
    지역 최적화를 회피하는데 유용

    단점
    대용량 데이터를 사용하여 적용할경우 시간이 매우 오래걸린다
    결과의 마지막 값을 확인하기 어렵다.

    미니-배치 경사하강법 : 모든 데이터를 입력하지 않고 데이터의 일부분만 입력해서 해당 값들의 경사도 평균을
    구해 가중치를 업데이트 하는 과정
    에포크 : 데이터를 한번에 모두 학습시키는 횟수를 의미
    배치 사이즈 : 한번에 학습이 되는 데이터의 개수를 의미한다.

    과대적합과 정규화
    과대적합 : 해당 모델이 특정 데이터셋에서만 작동하는 현상
    편향 : 모델의 결과가 얼마나 한족으로 쏠려 있는지를 나타내는 지표
    분산 : 예측값과 실제값과의 차이

    해결책
    더 많은 데이터 활용하기
    피쳐의 개수 줄이기
    적절한 매개변수 선정하기
    정규화 적용하기

    리지회귀 : L2정규화를 사용하며 선형 회귀 모델에 정규화(regularization) 항을 추가한 형태로, 과적합(overfitting)을 방지하고 모델의 일반화 성능을 향상시키기 위해 사용

    장점
    과적합을 방지하여 모델의 일반화 성능을 향상시킵니다.
    입력 데이터의 다중 공선성 문제를 완화합니다.

    단점
    일부 특성이 실제로 중요하지 않은 경우, 가중치를 완전히 0으로 만들지 못합니다(이는 Lasso 회귀와의 차이점입니다).

    라쏘회귀 : L1정규화를 사용하며 리지 회귀와 마찬가지로 선형 회귀 모델에 정규화 항을 추가한 형태이지만, L1 정규화를 사용하여 모델의 가중치를 제어

    장점
    특성 선택 기능을 통해 모델을 단순화하고 해석을 용이하게 만듭니다.
    과적합을 방지하여 모델의 일반화 성능을 향상시킵니다.

    단점
    높은 차원의 데이터에서 일부 중요한 특성의 정보도 손실될 수 있습니다.
    다중 공선성(multicollinearity) 문제에 대해서는 리지 회귀만큼 효과적이지 않을 수 있습니다.

    사이킷런을 이요한 선형회귀
    선형회귀관련함수
    LinearRegression : 가장 기본적인 선형회귀 알고리즘을 사용하며 SGD가 아닌 최소자승법으로 계산
    Lasso : L1 손실을 활용한 전용 알고리즘을 사용한다.
    Ridge : L2 손실을 활용한 전용 알고리즘을 사용한다.
    SGDRegressor : 확률적 경사 하강법을 사용한 회귀모델을 만든다. SGD에서 비용함수만을 변경하여 모든 함수를 지원하고 있어
    필요한 하이퍼 매개번수를 설정해야한다.

    Chapter9
    로지스틱 회귀의 기초

    로지스틱 회귀 : 예측 분석을 위한 회귀분석 중에서 특히 종속변수가 이분형일때 수행할 수 있는 회귀분석 비법의 한 종류이다.
    
    로지스틱 회귀의 기본함수
    가설함수
    hθ​(x)=σ(wTx)=1+e−wTx1​

    xx는 입력 특성(feature) 벡터
    ww는 모델의 가중치(weight) 벡터
    wTxwTx는 가중합 (weighted sum)
    σ(z)=11+e−zσ(z)=1+e−z1​는 시그모이드 함수


    비용함수
    J(w)=−m1​∑i=1m​[y(i)log(hθ​(x(i)))+(1−y(i))log(1−hθ​(x(i)))]

    mm은 훈련 샘플의 수
    y(i)y(i)는 i번째 샘플의 실제 레이블 (0 또는 1)
    hθ(x(i))hθ​(x(i))는 i번째 샘플에 대한 예측 확률

    분류 문제의 성능지표
    회귀 분류 클러스터링등이 존재

    혼동행렬 : 예측값이 실제값 대비 얼마나 잘 맞는지 2*2 행렬로 표현하는 기법

    혼동행렬표를 사용한 지표
    정확도 정밀도 민감도 F1 스코어등이 있다.

    Chapter10
    로지스틱 회귀의 심화

    다중클래스 분류와 소프트맥스 분류
    다중클래스 분류 : 2개이상의 클래스를 가진 y값에 대한 분류
    one vs all, onve vs one 두가지의 접근법이 있다.
    one vs all : m개의 클래스가 존재할때 각 클래스마다 분류기를 생성하여 분류하는 기법(소프트맥스분류)
    one vs one : m개의 클래스가 있다면, 이 클래스의 분류기를 하나의 클래스로 하고 나머지 클래스의 분류기들을
    만들어 최종적으로 각 분류기들의 결과를 투표로 결정하는 기법

    소프트 맥스 분류 : 로지스틱 회귀를 다중 클래스 상황으로 확장한 형태로, 각 클래스에 대한 확률을 출력하고 가장 높은 확률을 가진 클래스를 예측
    소프트 맥스 함수 : 다중클래스 분류에서 여러 선형회귀의 출력결과를 정규화하여 합이 1이 되도록 만드는 함수

    다중클래스 분류를 코드로 구현하기
    mnist데이터셋 : 손글씨를 숫자로 인식하는 이미지 분류 문제에서 가장 잘 활용되는 데이터셋

    ROC커브와 AUC
    ROC커브(Receiver Operating Characteristics) : 분류기의 임계값을 지속적으로 조정하여 정밀도와 민감도 간의 비율을
    도식화하여 표현하는 기법
    AUC : AUC (Area Under the Curve)는 이진 분류 모델의 성능을 평가하는 데 사용되는 중요한 지표 중 하나. AUC는 ROC 곡선 (Receiver Operating Characteristic curve) 아래의 면적을 나타내며, 모델의 분류 성능을 측정.

                                                    #2024. 6. 12

    Chpater11
    나이브 베이지안 분리기
    베이즈 정리의 이해
    베이즈 정리 : 두확률 변수의 사전확률과 사후확률 사이의 관계를 나타내는 정리. 객관적인 확률이 존재하지 않고 확률이 지속적으로
    업데이트된다는것

    20newsgroup으로 분류 연습하기
    20newsgroup데이터셋 : 텍스트 분류 작업을 시작할때 가장 먼저 다루는 입문용 데이터셋이며 사이킷런에 의해 제공된다.

    Chapter12
    의사결정트리 : 어떤 규칙을 하나의 트리형태로 표현한후 이를 바탕으로 분류나 회귀 문제를 해결하는것
    엔트로피 : 어떤 목적 달성을 위한 경우의 수를 정량적으로 표현하는 수치이다.

    의사결정트리 알고리즘
    정보이득 : 엔트로피를 사용하여 속성별 분류 시 데이터가 얼마나 순수한지를 측정하는 지표
    특징
    재귀적작동 : 의사결정트리 알고리즘은 재귀적으로 작동
    속성 기준으로 가지치기 수행 : 확실한 정보를 제공하는 속성을 기준으로 가지치기를 수행
    중요한 속성정보 제공

    의사결정트리의 확장
    C4.5알고리즘 : 로스퀸란이 제안한것으로 정보이득을 측정하는 방식을 좀더 평준화시켜 단순한 정보 값을 대신 사용한다.

    지니지수(Classification And Regression Trees)
    경제학에서 소득의 불평등도를 측정할 때 사용하는 지표

    의사결정트리 알고리즘의 다양한 변형
    트리 가지치기 : 의사 결정트리의 마지막 노드의 개수를 지정하여 트리의 깊이를 조정하는 방법
    사전 가지치기 : 처음 트리를 만들때 애초에 트리의 깊이나 마지막 노드의 최소 개수 등을 사전에 결정하여 입력하는 방식
    사후 가지치기 : 트리를 먼저 생성한 후 실험적으로 하이퍼 매개변수를 조정하는 방식

    Chpater13
    앙상블 : 여러개의 알고리즘들이 하나의 값을 예측하는 기법을 통칭

    투표분류기 : 앙상블 모델의 가장 기본적인 형태로 다수결 분류기라고도 한다.

    배깅과 랜덤 포레스트
    배깅 :  알고리즘의 단순성과 함께 트리계열 알고리즘과 매우 잘 맞아서 오늘날에도 가장 많이 사용되고 있는 기법
    부트스트래핑 : 모수 데이터로부터 학습 데이터를 추출할 때 임의의 데이터를 추출한후 복원 추출하는 여러번의 과정
    랜덤 포레스트 :  랜덤하게 숲을 생성하는 알고리즘으로 배깅 알고리즘을 의사결정트리에 적용한 모델

    부스팅
    부스팅 알고리즘 : 높은 성능을 내야하는 상황에서의 가장 좋은 선택지이며 간단하면서도 최적의 효과를 나타내는 특징이 있다.
    배깅과 부스팅의 차이점
    병렬화 가능 여부 : 부스팅은 병렬화를 지원하지 않는다.
    기준 추정치 : 부스팅은 각각의 모델에 편향이 높은 기준 추정치를 사용하여 개별 모델들은 과소적합이 발생하지만
    전체적으로 높은 성능을 낼수 있는 방향으로 학습
    성능차이 : 부스팅은 비용이 높은 알고리즘

    에이다부스트 : 매 라운드마다 인스턴스, 개별 데이터의 가중치를 계산하는 방식

    


